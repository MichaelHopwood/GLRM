{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import torch\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\r\n",
    "from datetime import datetime\r\n",
    "from models.handler import train, test, validate\r\n",
    "import pandas as pd\r\n",
    "from models.base_model import Model\r\n",
    "import numpy as np\r\n",
    "import json\r\n",
    "from data_loader.forecast_dataloader import ForecastDataset\r\n",
    "import torch.utils.data as torch_data\r\n",
    "import torch.nn as nn\r\n",
    "import time\r\n",
    "\r\n",
    "class Args:\r\n",
    "    def __init__(self):\r\n",
    "        self.train = True\r\n",
    "        self.evaluate = True\r\n",
    "        self.dataset = 'ECG_data'\r\n",
    "        self.window_size = 12\r\n",
    "        self.horizon = 3\r\n",
    "        self.train_length = 7\r\n",
    "        self.valid_length = 2\r\n",
    "        self.test_length = 1\r\n",
    "        self.epoch = 50\r\n",
    "        self.lr = 1e-4\r\n",
    "        self.multi_layer = 5\r\n",
    "        self.device = 'cpu'\r\n",
    "        self.validate_freq = 1\r\n",
    "        self.batch_size = 32\r\n",
    "        self.norm_method = 'z_score'\r\n",
    "        self.optimizer = 'RMSProp'\r\n",
    "        self.early_stop = False\r\n",
    "        self.exponential_decay_step = 5\r\n",
    "        self.decay_rate = 0.5\r\n",
    "        self.dropout_rate = 0.5\r\n",
    "        self.leakyrelu_rate = 0.2\r\n",
    "\r\n",
    "args = Args()\r\n",
    "print(f'Training configs: {args}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training configs: <__main__.Args object at 0x000002943B1FDD30>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_file = os.path.join('dataset', args.dataset + '.csv')\r\n",
    "result_train_file = os.path.join('output', args.dataset, 'train')\r\n",
    "result_test_file = os.path.join('output', args.dataset, 'test')\r\n",
    "if not os.path.exists(result_train_file):\r\n",
    "    os.makedirs(result_train_file)\r\n",
    "if not os.path.exists(result_test_file):\r\n",
    "    os.makedirs(result_test_file)\r\n",
    "data = pd.read_csv(data_file).values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# split data\r\n",
    "train_ratio = args.train_length / (args.train_length + args.valid_length + args.test_length)\r\n",
    "valid_ratio = args.valid_length / (args.train_length + args.valid_length + args.test_length)\r\n",
    "test_ratio = 1 - train_ratio - valid_ratio\r\n",
    "train_data = data[:int(train_ratio * len(data))]\r\n",
    "valid_data = data[int(train_ratio * len(data)):int((train_ratio + valid_ratio) * len(data))]\r\n",
    "test_data = data[int((train_ratio + valid_ratio) * len(data)):]\r\n",
    "\r\n",
    "torch.manual_seed(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2943b579a50>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "result_file = result_train_file\r\n",
    "\r\n",
    "node_cnt = train_data.shape[1]\r\n",
    "model = Model(node_cnt, 2, args.window_size, args.multi_layer, horizon=args.horizon)\r\n",
    "model.to(args.device)\r\n",
    "if len(train_data) == 0:\r\n",
    "    raise Exception('Cannot organize enough training data')\r\n",
    "if len(valid_data) == 0:\r\n",
    "    raise Exception('Cannot organize enough validation data')\r\n",
    "\r\n",
    "if args.norm_method == 'z_score':\r\n",
    "    train_mean = np.mean(train_data, axis=0)\r\n",
    "    train_std = np.std(train_data, axis=0)\r\n",
    "    normalize_statistic = {\"mean\": train_mean.tolist(), \"std\": train_std.tolist()}\r\n",
    "elif args.norm_method == 'min_max':\r\n",
    "    train_min = np.min(train_data, axis=0)\r\n",
    "    train_max = np.max(train_data, axis=0)\r\n",
    "    normalize_statistic = {\"min\": train_min.tolist(), \"max\": train_max.tolist()}\r\n",
    "else:\r\n",
    "    normalize_statistic = None\r\n",
    "if normalize_statistic is not None:\r\n",
    "    with open(os.path.join(result_file, 'norm_stat.json'), 'w') as f:\r\n",
    "        json.dump(normalize_statistic, f)\r\n",
    "\r\n",
    "if args.optimizer == 'RMSProp':\r\n",
    "    my_optim = torch.optim.RMSprop(params=model.parameters(), lr=args.lr, eps=1e-08)\r\n",
    "else:\r\n",
    "    my_optim = torch.optim.Adam(params=model.parameters(), lr=args.lr, betas=(0.9, 0.999))\r\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=args.decay_rate)\r\n",
    "\r\n",
    "train_set = ForecastDataset(train_data, window_size=args.window_size, horizon=args.horizon,\r\n",
    "                            normalize_method=args.norm_method, norm_statistic=normalize_statistic)\r\n",
    "valid_set = ForecastDataset(valid_data, window_size=args.window_size, horizon=args.horizon,\r\n",
    "                            normalize_method=args.norm_method, norm_statistic=normalize_statistic)\r\n",
    "train_loader = torch_data.DataLoader(train_set, batch_size=args.batch_size, drop_last=False, shuffle=True,\r\n",
    "                                        num_workers=0)\r\n",
    "valid_loader = torch_data.DataLoader(valid_set, batch_size=args.batch_size, shuffle=False, num_workers=0)\r\n",
    "\r\n",
    "forecast_loss = nn.MSELoss(reduction='mean').to(args.device)\r\n",
    "\r\n",
    "total_params = 0\r\n",
    "for name, parameter in model.named_parameters():\r\n",
    "    if not parameter.requires_grad: continue\r\n",
    "    param = parameter.numel()\r\n",
    "    total_params += param\r\n",
    "print(f\"Total Trainable Params: {total_params}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Trainable Params: 1123303\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "best_validate_mae = np.inf\r\n",
    "validate_score_non_decrease_count = 0\r\n",
    "performance_metrics = {}\r\n",
    "for epoch in range(args.epoch):\r\n",
    "    epoch_start_time = time.time()\r\n",
    "    model.train()\r\n",
    "    loss_total = 0\r\n",
    "    cnt = 0\r\n",
    "    for i, (inputs, target) in enumerate(train_loader):\r\n",
    "        inputs = inputs.to(args.device)\r\n",
    "        target = target.to(args.device)\r\n",
    "        model.zero_grad()\r\n",
    "        forecast, _ = model(inputs)\r\n",
    "        loss = forecast_loss(forecast, target)\r\n",
    "        cnt += 1\r\n",
    "        loss.backward()\r\n",
    "        my_optim.step()\r\n",
    "        loss_total += float(loss)\r\n",
    "\r\n",
    "        \r\n",
    "        break\r\n",
    "\r\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | train_total_loss {:5.4f}'.format(epoch, (\r\n",
    "            time.time() - epoch_start_time), loss_total / cnt))\r\n",
    "    \r\n",
    "    break\r\n",
    "        \r\n",
    "\r\n",
    "    # save_model(model, result_file, epoch)\r\n",
    "    \r\n",
    "    if (epoch+1) % args.exponential_decay_step == 0:\r\n",
    "        my_lr_scheduler.step()\r\n",
    "    if (epoch + 1) % args.validate_freq == 0:\r\n",
    "        is_best_for_now = False\r\n",
    "        print('------ validate on data: VALIDATE ------')\r\n",
    "        performance_metrics = \\\r\n",
    "            validate(model, valid_loader, args.device, args.norm_method, normalize_statistic,\r\n",
    "                        node_cnt, args.window_size, args.horizon,\r\n",
    "                        result_file=result_file)\r\n",
    "        if best_validate_mae > performance_metrics['mae']:\r\n",
    "            best_validate_mae = performance_metrics['mae']\r\n",
    "            is_best_for_now = True\r\n",
    "            validate_score_non_decrease_count = 0\r\n",
    "        else:\r\n",
    "            validate_score_non_decrease_count += 1\r\n",
    "        # save model\r\n",
    "        # if is_best_for_now:\r\n",
    "        #     save_model(model, result_file)\r\n",
    "    # early stop\r\n",
    "    if args.early_stop and validate_score_non_decrease_count >= args.early_stop_step:\r\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input size: torch.Size([32, 12, 140])\n",
      "reformat: torch.Size([140, 32, 12])\n",
      "After GRU torch.Size([140, 32, 140])\n",
      "After reformat torch.Size([32, 140, 140])\n",
      "into graph attention:  torch.Size([32, 140, 140])\n",
      "reformat torch.Size([32, 140, 140])\n",
      "key=Input*WeightKey size torch.Size([32, 140, 1]) = <built-in method size of Tensor object at 0x0000029421045168> torch.Size([140, 1])\n",
      "query=input*weightQuery size torch.Size([32, 140, 1]) = torch.Size([32, 140, 140]) torch.Size([140, 1])\n",
      "define data = key.repeat(1, 1, N).view(bat, N * N, 1) + query.repeat(1, N, 1) torch.Size([32, 19600, 1]) torch.Size([32, 19600, 1]) torch.Size([32, 19600, 1])\n",
      "squeeze data: torch.Size([32, 19600])\n",
      "view data torch.Size([32, 140, 140])\n",
      "pass leakyrelu torch.Size([32, 140, 140])\n",
      "compute attention torch.Size([32, 140, 140])\n",
      "dropout on attention:  torch.Size([32, 140, 140])\n",
      "Attention mean'd on dim 0 torch.Size([140, 140])\n",
      "Degree = attention sum on dim 1 torch.Size([140])\n",
      "attention refactor torch.Size([140, 140])\n",
      "degree_L torch.Size([140, 140])\n",
      "diagonal_degree_hat torch.Size([140, 140])\n",
      "laplacian = diagonal_degree_hat * ((degree_l - attention) * diagonal_degree_hat) torch.Size([140, 140])\n",
      "laplacian into chebychev polynomial: torch.Size([140, 140])\n",
      "unsqueeze\n",
      "mul_L size torch.Size([4, 140, 140])\n",
      "final attention size torch.Size([140, 140])\n",
      "X squeezed size: torch.Size([32, 1, 140, 12])\n",
      "starting stock block # 0\n",
      "In stock block\n",
      "\tx torch.Size([32, 1, 140, 12])\n",
      "\tmul_L torch.Size([4, 140, 140])\n",
      "\tunsqueeze 1 on mulL torch.Size([4, 1, 140, 140])\n",
      "\tunsqueeze 1 on x torch.Size([32, 1, 1, 140, 12])\n",
      "\tgfted=mul_L*x torch.Size([32, 4, 1, 140, 12])\n",
      "\tInto SPE SEQ CELL torch.Size([32, 4, 1, 140, 12])\n",
      "\tview input torch.Size([32, 4, 140, 12])\n",
      "\tffted torch.Size([32, 4, 140, 12, 2])\n",
      "\treal torch.Size([32, 140, 48])\n",
      "\timg torch.Size([32, 140, 48])\n",
      "\tStarting GLUs\n",
      "\t\t iteration # 0\n",
      "\t\t real torch.Size([32, 140, 240])\n",
      "\t\t img torch.Size([32, 140, 240])\n",
      "\t\t iteration # 1\n",
      "\t\t real torch.Size([32, 140, 240])\n",
      "\t\t img torch.Size([32, 140, 240])\n",
      "\t\t iteration # 2\n",
      "\t\t real torch.Size([32, 140, 240])\n",
      "\t\t img torch.Size([32, 140, 240])\n",
      "\treal and unsqueeze real torch.Size([32, 4, 140, 60]) torch.Size([32, 4, 140, 60, 1])\n",
      "\timg and unsqueeze img torch.Size([32, 4, 140, 60]) torch.Size([32, 4, 140, 60, 1])\n",
      "\tTimestep as inner = cat(real unsqueeze, img unsqueeze, dim=-1) torch.Size([32, 4, 140, 60, 2])\n",
      "\tOut iffted torch.Size([32, 4, 140, 60])\n",
      "\tgconv_input = output iffted unsqueeze 2:  torch.Size([32, 4, 1, 140, 60])\n",
      "\tigfted = gconv_input * weight <built-in method size of Tensor object at 0x00000294210EFAF8> <built-in method size of Tensor object at 0x00000294210EFF78> torch.Size([1, 4, 1, 60, 60])\n",
      "\tigfted summed on dim 1: torch.Size([32, 1, 140, 60])\n",
      "\tsigmoid( forecast squeezed ): torch.Size([32, 140, 60])\n",
      "\tforecast_result:  torch.Size([32, 140, 12])\n",
      "\tbackcast linear layer on x and squeezed torch.Size([32, 1, 140, 12])\n",
      "\tsigmoid ( backcast linear layer on igfted MINUS backcast_short ) torch.Size([32, 1, 140, 12])\n",
      "\tout stock block: forecast and backcast_source torch.Size([32, 140, 12]) torch.Size([32, 1, 140, 12])\n",
      "starting stock block # 1\n",
      "In stock block\n",
      "\tx torch.Size([32, 1, 140, 12])\n",
      "\tmul_L torch.Size([4, 140, 140])\n",
      "\tunsqueeze 1 on mulL torch.Size([4, 1, 140, 140])\n",
      "\tunsqueeze 1 on x torch.Size([32, 1, 1, 140, 12])\n",
      "\tgfted=mul_L*x torch.Size([32, 4, 1, 140, 12])\n",
      "\tInto SPE SEQ CELL torch.Size([32, 4, 1, 140, 12])\n",
      "\tview input torch.Size([32, 4, 140, 12])\n",
      "\tffted torch.Size([32, 4, 140, 12, 2])\n",
      "\treal torch.Size([32, 140, 48])\n",
      "\timg torch.Size([32, 140, 48])\n",
      "\tStarting GLUs\n",
      "\t\t iteration # 0\n",
      "\t\t real torch.Size([32, 140, 240])\n",
      "\t\t img torch.Size([32, 140, 240])\n",
      "\t\t iteration # 1\n",
      "\t\t real torch.Size([32, 140, 240])\n",
      "\t\t img torch.Size([32, 140, 240])\n",
      "\t\t iteration # 2\n",
      "\t\t real torch.Size([32, 140, 240])\n",
      "\t\t img torch.Size([32, 140, 240])\n",
      "\treal and unsqueeze real torch.Size([32, 4, 140, 60]) torch.Size([32, 4, 140, 60, 1])\n",
      "\timg and unsqueeze img torch.Size([32, 4, 140, 60]) torch.Size([32, 4, 140, 60, 1])\n",
      "\tTimestep as inner = cat(real unsqueeze, img unsqueeze, dim=-1) torch.Size([32, 4, 140, 60, 2])\n",
      "\tOut iffted torch.Size([32, 4, 140, 60])\n",
      "\tgconv_input = output iffted unsqueeze 2:  torch.Size([32, 4, 1, 140, 60])\n",
      "\tigfted = gconv_input * weight <built-in method size of Tensor object at 0x000002947F9FDA68> <built-in method size of Tensor object at 0x00000294210458B8> torch.Size([1, 4, 1, 60, 60])\n",
      "\tigfted summed on dim 1: torch.Size([32, 1, 140, 60])\n",
      "\tsigmoid( forecast squeezed ): torch.Size([32, 140, 60])\n",
      "\tforecast_result:  torch.Size([32, 140, 12])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f96c226cec25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mforecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\UCF\\Dissertation\\GLRM\\models\\base_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstack_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'starting stock block #'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[0mforecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstock_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstack_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmul_L\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mforecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\UCF\\Dissertation\\GLRM\\models\\base_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mul_L)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mbackcast_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\tout stock block: forecast and backcast_source'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackcast_source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackcast_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "rnn = nn.GRU(10, 20, 2)\r\n",
    "input = torch.randn(5, 3, 10)\r\n",
    "h0 = torch.randn(2, 3, 20)\r\n",
    "output, hn = rnn(input, h0)\r\n",
    "\r\n",
    "\r\n",
    "input.size(), output.size(), hn.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([5, 3, 20]), torch.Size([2, 3, 20]))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "7c28e26739430500fec97d508cbac2e5d4a112deb445b412c4e69aa96f605479"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}